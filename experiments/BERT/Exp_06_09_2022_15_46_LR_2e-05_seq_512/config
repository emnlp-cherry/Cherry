Device:cuda:0
Pretrained_model:bert-base-uncased
Freeze_pretrained:True
Batch_size:8
Learning_rate:2e-05
Epochs:5
Droput:0.0
Prediction_threshold:0.5
Max_sequence_length:512
Validation_type:holdout
Experiment highlights: increased context length to 512