Device:cuda:0
Pretrained_model:bert-base-uncased
Freeze_pretrained:True
Batch_size:8
Learning_rate:2e-05
Epochs:5
Droput:0.0
Prediction_threshold:0.5
Max_sequence_length:128
Validation_type:holdout
Classification_type:1
Experiment highlights: decreased context size to 128